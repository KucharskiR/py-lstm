{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n",
      "File \u001b[1;32mc:\\Users\\Dell\\.conda\\envs\\tf_env\\lib\\site-packages\\tensorflow\\__init__.py:29\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_inspect\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_logging\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:982\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:925\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\.conda\\envs\\tf_env\\lib\\site-packages\\_distutils_hack\\__init__.py:97\u001b[0m, in \u001b[0;36mDistutilsMetaFinder.find_spec\u001b[1;34m(self, fullname, path, target)\u001b[0m\n\u001b[0;32m     95\u001b[0m method_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspec_for_\u001b[39m\u001b[38;5;132;01m{fullname}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlocals\u001b[39m())\n\u001b[0;32m     96\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_name, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\.conda\\envs\\tf_env\\lib\\site-packages\\_distutils_hack\\__init__.py:108\u001b[0m, in \u001b[0;36mDistutilsMetaFinder.spec_for_distutils\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 108\u001b[0m     mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msetuptools._distutils\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# There are a couple of cases where setuptools._distutils\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# may not be present:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m#   has been loaded. Ref #2980.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# In either case, fall back to stdlib behavior.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\.conda\\envs\\tf_env\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\.conda\\envs\\tf_env\\lib\\site-packages\\setuptools\\__init__.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdepends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Require\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscovery\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PackageFinder, PEP420PackageFinder\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Distribution\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Extension\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SetuptoolsDeprecationWarning\n",
      "File \u001b[1;32mc:\\Users\\Dell\\.conda\\envs\\tf_env\\lib\\site-packages\\setuptools\\dist.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m command \u001b[38;5;28;01mas\u001b[39;00m _  \u001b[38;5;66;03m# noqa  -- imported for side-effects\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_importlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setupcfg, pyprojecttoml\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscovery\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfigDiscovery\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmonkey\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_unpatched\n",
      "File \u001b[1;32mc:\\Users\\Dell\\.conda\\envs\\tf_env\\lib\\site-packages\\setuptools\\config\\__init__.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, TypeVar, cast\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SetuptoolsDeprecationWarning\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setupcfg\n\u001b[0;32m     10\u001b[0m Fn \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFn\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39mCallable)\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_configuration\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_configuration\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\.conda\\envs\\tf_env\\lib\\site-packages\\setuptools\\config\\setupcfg.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextern\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidVersion, Version\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SetuptoolsDeprecationWarning\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m expand\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributionMetadata  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\.conda\\envs\\tf_env\\lib\\site-packages\\setuptools\\config\\expand.py:49\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleType\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistutilsOptionError\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m same_path \u001b[38;5;28;01mas\u001b[39;00m _same_path\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SetuptoolsWarning\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:982\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:925\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1423\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1395\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1555\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:156\u001b[0m, in \u001b[0;36m_path_isfile\u001b[1;34m(path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:148\u001b[0m, in \u001b[0;36m_path_is_mode_type\u001b[1;34m(path, mode)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:142\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "# from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "# be able to save images on server\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# !pip install -U kaleido\n",
    "# import kaleido #required\n",
    "# kaleido.__version__ #0.2.1\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip\n",
    "# importing the \"tarfile\" module\n",
    "import tarfile # type: ignore\n",
    "\n",
    "# open file\n",
    "file = tarfile.open('1_150x9.tar.gz')\n",
    "\n",
    "# extracting a specific file\n",
    "file.extractall(path='./1_150x9/')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator\n",
    "def data():\n",
    "    timestepsPerSample = 150\n",
    "\n",
    "    # Replace 'your_file.csv' with the actual file path\n",
    "    file_features = './1_150x9/1_150x9f.csv'\n",
    "    file_labels = './1_150x9/1_150x9l.csv'\n",
    "\n",
    "    # Read the .csv file and create an array\n",
    "    data_strings = np.genfromtxt(file_features, delimiter=';')\n",
    "    labels_strings = np.genfromtxt(file_labels,delimiter=';')\n",
    "\n",
    "    # Wycinanie wybranych kolumn\n",
    "    # data_s = data_strings[:,[0,2,3,4,5,6,7,8]]\n",
    "    data_s = data_strings[:,[0,4,5,8]]\n",
    "    num_features = data_s.shape[1]\n",
    "    # print(data_strings[:3])\n",
    "    # print(data_s[:3])\n",
    "    \n",
    "    # Convert from strings to float and int\n",
    "    X = data_s.astype(float).reshape((-1,timestepsPerSample,num_features))\n",
    "    Y = labels_strings.astype(float).reshape((-1,3))\n",
    "    # print(X.shape)\n",
    "    # print(Y.shape)\n",
    "\n",
    "    # Modification from imported to new size\n",
    "    X_mod = X[1000:11000,130:]\n",
    "    Y_mod = Y[1000:11000]\n",
    "    timestepsPerSample = X_mod.shape[1]\n",
    "    # print(X_mod.shape)\n",
    "    # print(Y_mod.shape)\n",
    "    # print(X_mod[:1])\n",
    "\n",
    "    # Splitting\n",
    "    x_train, x_test, Y_train, Y_test = train_test_split(X_mod,Y_mod, test_size=0.15, shuffle=False)\n",
    "    print(x_train.shape)\n",
    "    y_train = Y_train[:, 0:2]\n",
    "    y_test = Y_test[:, 0:2]\n",
    "    # print(y_train[:2])\n",
    "    # print(y_test[:2])\n",
    "\n",
    "    # Summarize\n",
    "    num_samples = x_train.shape[0]\n",
    "    print(f\"Timesteps: {timestepsPerSample}\")\n",
    "    print(f\"Num Samples: {num_samples}\")\n",
    "    print(f\"Num features: {num_features}\")\n",
    "    return x_train, x_test, y_train, y_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit lstm model\n",
    "def fit_lstmModel(x_train, y_train, x_test, y_test, batch_size, nb_epoch, neurons):\n",
    "    LstmLayer = LSTM(\n",
    "    units=neurons,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_activation=\"sigmoid\",\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    recurrent_initializer=\"orthogonal\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    unit_forget_bias=True,\n",
    "    kernel_regularizer=None,\n",
    "    recurrent_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    recurrent_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    dropout=0.2,\n",
    "    recurrent_dropout=0.0,\n",
    "    seed=None,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    "    unroll=False,\n",
    "    input_shape=(x_train.shape[1],x_train.shape[2])\n",
    "    )\n",
    "\n",
    "    num_samples = x_train.shape[0]\n",
    "    STEPS_PER_EPOCH = num_samples/batch_size\n",
    "\n",
    "    model = Sequential() # initializing model\n",
    "    # input layer and LSTM layer with 50 neurons\n",
    "    model.add(LstmLayer)\n",
    "    # model.add(Dense(100, activation='relu'))\n",
    "    # model.add(Dense(100, activation='relu'))\n",
    "    # model.add(Dense(20, activation='relu'))\n",
    "    # outpute layer with sigmoid activation\n",
    "    model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "    # lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.001,\n",
    "    decay_steps=STEPS_PER_EPOCH*100,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "\n",
    "    def get_optimizer():\n",
    "         # return tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        return tf.keras.optimizers.Adam(learning_rate= lr_schedule) # type: ignore\n",
    "\n",
    "    optimizer = get_optimizer()\n",
    "\n",
    "    # defining loss function, optimizer, metrics and then compiling model\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(x_train, y_train, epochs=nb_epoch, batch_size=batch_size, \n",
    "                        shuffle=False, validation_data=(x_test, y_test), verbose=1) # type: ignore\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profit\n",
    "def funcProfit(predict, Y_test):\n",
    "    predict_classes = np.where(predict > 0.5, 1,0)\n",
    "    concat = np.hstack((predict_classes, Y_test[:,2:]))\n",
    "    df = pd.DataFrame(concat, columns=['Sell', 'Buy', 'Price'])\n",
    "\n",
    "    # Absolute difference prices\n",
    "    sum = 0\n",
    "    for i in range(0, len(df)):\n",
    "        if (i-1) > 0:\n",
    "            diff = abs((df.at[i,'Price'] - df.at[i-1,'Price']))\n",
    "            if diff < 0.5:\n",
    "                if df.at[i,'Sell'] == 1:\n",
    "                    sum += (df.at[i,'Price'] - df.at[i-1,'Price'])*(-1)\n",
    "                elif df.at[i,'Buy'] == 1:\n",
    "                    sum += (df.at[i,'Price'] - df.at[i-1,'Price'])\n",
    "                if df.at[i,'Sell'] != df.at[i-1,'Sell']:\n",
    "                    sum -= 0.03\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment\n",
    "def experiment(repeats, epochs):\n",
    "    # Data gen\n",
    "    x_train, x_test, y_train, y_test, Y_test = data()\n",
    "\n",
    "    # Evaluate declaration\n",
    "    accuracy = list()\n",
    "    profit = list()\n",
    "    metrics = list()\n",
    "\n",
    "    # Repeats\n",
    "    for r in range(repeats):\n",
    "        batch_size = 4\n",
    "        # model\n",
    "        model, history = fit_lstmModel(x_train, y_train, x_test, y_test, batch_size, epochs, 5)\n",
    "\n",
    "        # forecast the entire training dataset to build up state for forecasting\n",
    "        predict = model.predict(x_test, batch_size=batch_size)\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0) # type: ignore\n",
    "\n",
    "        metric = pd.DataFrame(history.history)\n",
    "        metric['epoch'] = history.epoch\n",
    "\n",
    "        metrics.append(metric)\n",
    "        accuracy.append(test_acc*100)\n",
    "        profit.append(funcProfit(predict, Y_test))\n",
    "    \n",
    "    return accuracy, profit, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "repeats = 1\n",
    "results_acc = DataFrame()\n",
    "results_profit = DataFrame()\n",
    "metrics = list()\n",
    "# vary training epochs\n",
    "epochs = [1]\n",
    "for e in epochs:\n",
    " results_acc[str(e)], results_profit[str(e)], metrics = experiment(repeats, e)\n",
    "# summarize results\n",
    "print(results_acc.describe())\n",
    "print(results_profit.describe())\n",
    "\n",
    "# save boxplot\n",
    "pyplot.subplot(1, 2, 1)\n",
    "results_acc.boxplot()\n",
    "pyplot.subplot(1, 2, 2)\n",
    "results_profit.boxplot()\n",
    "pyplot.savefig(f'boxplot_{str(epochs)}.png')\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "for idx, m in enumerate(metrics):\n",
    "    fig.add_trace(go.Scatter(x=m['epoch'], y=m['accuracy'], name=f'accuracy{str(idx)}', line_color='#0000ff', showlegend=False), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=m['epoch'], y=m['loss'], name=f'loss{str(idx)}', line_color='#0000ff', showlegend=False), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=m['epoch'], y=m['val_accuracy'], name=f'val_accuracy{str(idx)}', line_color='#EF8260', showlegend=False), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=m['epoch'], y=m['val_loss'], name=f'val_loss{str(idx)}', line_color='#EF8260', showlegend=False), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text='epochs')\n",
    "fig.update_yaxes(title_text='accuracy')\n",
    "fig.update_layout(width=1000, title='Accuracy and Loss')\n",
    "fig.write_image(file=f\"compare_models_{str(epochs)}.jpg\", engine=\"kaleido\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
