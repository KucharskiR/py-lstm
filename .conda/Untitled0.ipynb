{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1653698,"status":"ok","timestamp":1704989169666,"user":{"displayName":"RadosÅ‚aw Kucharski","userId":"10786392646240796891"},"user_tz":-60},"id":"51o6kObaoKAk","outputId":"03bca5f2-3fc0-41b2-f5fb-b89c0112ce62"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n","File \u001b[1;32mc:\\Users\\kucha\\Documents\\Python_Projects\\lstm\\.conda\\Lib\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"]}],"source":["import csv\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers import Dense\n","from keras.optimizers import Adam\n","from keras.callbacks import LambdaCallback\n","from keras.initializers import TruncatedNormal\n","# import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n","\n","# Replace 'your_file.csv' with the actual file path\n","path = 'c:\\\\Users\\\\kucha\\\\AppData\\\\Roaming\\\\MetaQuotes\\\\Terminal\\\\CF48736A04CB4E277F336167170AB43B\\\\MQL4\\\\Files\\\\ai_data\\\\01\\\\'\n","file_path = path + 'features\\\\' + '27.csv'\n","file_labels = path + 'labels\\\\' + '27.csv'\n","\n","# Specify the CSV file name\n","csv_file_name = 'my_data.csv'\n","\n","# Assuming there are three features in your data\n","num_features = 6\n","num_labels = 2\n","num_samples = 1980\n","timestepsPerSample = 120\n","epochs = 200\n","batch = 30\n","\n","# Read the .csv file and create an array\n","data_strings = np.genfromtxt(file_path, delimiter=';')\n","labels_strings = np.genfromtxt(file_labels,delimiter=';')\n","\n","# Convert from strings to float and int\n","X = data_strings.astype(float).reshape((num_samples,timestepsPerSample,num_features))\n","Y = labels_strings.astype(float).reshape((num_samples,num_labels))\n","\n","# splitting the dataset 75% for training and 25% testing\n","# X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n","X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, shuffle=False)\n","\n","# X_train = X_train.to_numpy()\n","x_train = X_train\n","\n","lst = Sequential() # initializing model\n","\n","# input layer and LSTM layer with 50 neurons\n","lst.add(LSTM(units=200, return_sequences=False, input_shape=(x_train.shape[1],x_train.shape[2])))\n","lst.add(Dense(100, activation='relu'))\n","lst.add(Dense(50, activation='relu'))\n","lst.add(Dense(25, activation='relu'))\n","# outpute layer with sigmoid activation\n","lst.add(Dense(num_labels, activation='sigmoid'))\n","\n","# defining loss function, optimizer, metrics and then compiling model\n","lst.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","# training the model on training dataset\n","history = lst.fit(x_train, y_train, epochs=epochs, batch_size=batch,validation_split=0.2)\n","\n","# x_test = np.reshape(X_test, (X_test.shape[0],timestepsPerSample,X_test.shape[1]))\n","x_test = X_test\n","\n","# predicting target attribute on testing dataset\n","predict = lst.predict(x_test)\n","\n","# Set print options to suppress scientific notation\n","np.set_printoptions(suppress=True)\n","\n","# Concatenate arrays\n","result = np.hstack((predict, y_test))\n","print(result)\n","\n","test_results = lst.evaluate(x_test, y_test, verbose=1)\n","print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')\n","\n","# Create a DataFrame from the 2D array\n","df = pd.DataFrame(predict, columns=['Column1', 'Column2'])\n","\n","# Export the DataFrame to CSV with semicolon as the delimiter and avoiding scientific notation\n","df.to_csv(csv_file_name, sep=';', index=False, float_format='%.0f')\n","\n","# Read the CSV file into a DataFrame without header\n","df = pd.read_csv(csv_file_name, sep=';', header=None)\n","\n","# Drop the first row containing data\n","df = df.iloc[1:]\n","\n","# Save the modified DataFrame back to the CSV file without header\n","df.to_csv(csv_file_name, sep=';', index=False, header=False)\n","\n","print(f'CSV file name: {csv_file_name}.')\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO7+RumybKUdbIF0EPC7XCv","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
