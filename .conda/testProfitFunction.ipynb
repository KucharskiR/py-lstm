{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intallation packages before use Jupyter\n",
    "\n",
    "# !pip install pandas\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install keras\n",
    "# !pip install matplotlib\n",
    "# !pip install kaleido\n",
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "# from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "# be able to save images on server\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# Not show warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# !pip install -U kaleido # w Google Colab wymagany Runtime restart po instalacji (Runtime -> Restart Runtime)\n",
    "# import kaleido #required\n",
    "# kaleido.__version__ #0.2.1\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip\n",
    "# importing the \"tarfile\" module\n",
    "import tarfile # type: ignore\n",
    "\n",
    "# open file\n",
    "file = tarfile.open('../data/2_150x9.tar.gz')\n",
    "\n",
    "# extracting a specific file\n",
    "file.extractall(path='../data/2_150x9/')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator\n",
    "def data(time):\n",
    "    # Timestep \n",
    "    # timestepsPerSample = 20\n",
    "    timestepsPerSample = time\n",
    "\n",
    "    # Timesteps in input data\n",
    "    timestepsPerSampleWholeData = 150\n",
    "\n",
    "    # Replace 'your_file.csv' with the actual file path\n",
    "    file_features = '../data/2_150x9/2_150x9f.csv'\n",
    "    file_labels = '../data/2_150x9/2_150x9l.csv'\n",
    "\n",
    "    # Read the .csv file and create an array\n",
    "    data_strings = np.genfromtxt(file_features, delimiter=';')\n",
    "    labels_strings = np.genfromtxt(file_labels,delimiter=';')\n",
    "\n",
    "    # Wycinanie wybranych kolumn\n",
    "    #  0    1         2             3        4       5        6    7        8\n",
    "    # RSI, VWAP, HeikenResult, closeHeiken, CMF, Stochastic, OBV, QQE, TrendFilter\n",
    "    # data_s = data_strings[:,[0,2,3,4,5,6,7,8]]\n",
    "    data_s = data_strings[:,[0,4,5,8]]\n",
    "    num_features = data_s.shape[1]\n",
    "    # print(data_strings[:3])\n",
    "    # print(data_s[:3])\n",
    "    \n",
    "    # Convert from strings to float and int\n",
    "    X = data_s.astype(float).reshape((-1,timestepsPerSampleWholeData,num_features))\n",
    "    Y = labels_strings.astype(float).reshape((-1,6))\n",
    "    # print(X.shape)\n",
    "    # print(Y.shape)\n",
    "\n",
    "    # Modification from imported to new size X[samples,timesteps]\n",
    "    X_mod = X[1000:1066,timestepsPerSampleWholeData - timestepsPerSample:]\n",
    "    Y_mod = Y[1000:1066]\n",
    "    # X_mod = X[1000:1020,timestepsPerSampleWholeData - timestepsPerSample:]\n",
    "    # Y_mod = Y[1000:1020]\n",
    "    timestepsPerSampleWholeData = X_mod.shape[1]\n",
    "    # print(X_mod.shape)\n",
    "    # print(Y_mod.shape)\n",
    "    # print(X_mod[:1])\n",
    "\n",
    "    # Splitting\n",
    "    x_train, x_test, Y_train, Y_test = train_test_split(X_mod,Y_mod, test_size=0.15, shuffle=False)\n",
    "    y_train = Y_train[:, 0:2]\n",
    "    y_test = Y_test[:, 0:2]\n",
    "    # print(y_train[:2])\n",
    "    # print(y_test[:2])\n",
    "\n",
    "    # Summarize\n",
    "    num_samples = x_train.shape[0]\n",
    "    test_samples = x_test.shape[0]\n",
    "    print(f\"Train shape: {x_train.shape}\")\n",
    "    print(f\"Timesteps: {timestepsPerSampleWholeData}\")\n",
    "    print(f\"Num Samples: {num_samples}\")\n",
    "    print(f\"Test Samples: {test_samples}\")\n",
    "    print(f\"Num features: {num_features}\")\n",
    "    return x_train, x_test, y_train, y_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit lstm model\n",
    "from tabnanny import verbose\n",
    "\n",
    "\n",
    "def fit_lstmModel(x_train, y_train, x_test, y_test, batch_size, nb_epoch, neurons, denseType, dropout, model):\n",
    "    if model == 0:\n",
    "        LstmLayer = LSTM(\n",
    "        units=neurons,\n",
    "        activation=\"tanh\",\n",
    "        recurrent_activation=\"sigmoid\",\n",
    "        use_bias=True, # true if cuDNN\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        recurrent_initializer=\"orthogonal\",\n",
    "        bias_initializer=\"zeros\",\n",
    "        unit_forget_bias=True,\n",
    "        kernel_regularizer=None,\n",
    "        recurrent_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        recurrent_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        dropout=dropout, # !important parameter for optimization => 0 if cuDNN\n",
    "        recurrent_dropout=0.0,\n",
    "        seed=None,\n",
    "        return_sequences=False,\n",
    "        return_state=False,\n",
    "        go_backwards=False,\n",
    "        stateful=False,\n",
    "        unroll=False, # false if cuDNN\n",
    "        input_shape=(x_train.shape[1],x_train.shape[2]),\n",
    "        # input_dim=(x_train.shape[1])\n",
    "        )\n",
    "\n",
    "        if denseType == 0:\n",
    "            model = Sequential() # initializing model\n",
    "            # input layer and LSTM layer with 50 neurons\n",
    "            model.add(LstmLayer)\n",
    "            # model.add(Dense(100, activation='relu'))\n",
    "            # model.add(Dense(100, activation='relu'))\n",
    "            # model.add(Dense(20, activation='relu'))\n",
    "            # outpute layer with sigmoid activation\n",
    "            model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "        elif denseType == 1:\n",
    "            model = Sequential() # initializing model\n",
    "            # input layer and LSTM layer with 50 neurons\n",
    "            model.add(LstmLayer)\n",
    "            model.add(Dense(100, activation='relu'))\n",
    "            # model.add(Dense(100, activation='relu'))\n",
    "            # model.add(Dense(20, activation='relu'))\n",
    "            # outpute layer with sigmoid activation\n",
    "            model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "        elif denseType == 2:\n",
    "            model = Sequential() # initializing model\n",
    "            # input layer and LSTM layer with 50 neurons\n",
    "            model.add(LstmLayer)\n",
    "            model.add(Dense(100, activation='relu'))\n",
    "            model.add(Dense(100, activation='relu'))\n",
    "            # model.add(Dense(20, activation='relu'))\n",
    "            # outpute layer with sigmoid activation\n",
    "            model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "        elif denseType == 3:\n",
    "            model = Sequential() # initializing model\n",
    "            # input layer and LSTM layer with 50 neurons\n",
    "            model.add(LstmLayer)\n",
    "            model.add(Dense(100, activation='relu'))\n",
    "            model.add(Dense(100, activation='relu'))\n",
    "            model.add(Dense(20, activation='relu'))\n",
    "            # outpute layer with sigmoid activation\n",
    "            model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "    elif model == 1:\n",
    "        model = Sequential()\n",
    "\n",
    "        # Assuming `data` is your input matrix with shape (samples, time_steps, features)\n",
    "        model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(LSTM(units=50, return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Dense(units=25))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        # Output layer for price prediction\n",
    "        model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "    \n",
    "    num_samples = x_train.shape[0]\n",
    "    STEPS_PER_EPOCH = num_samples/batch_size\n",
    "\n",
    "    # lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.001,\n",
    "    decay_steps=STEPS_PER_EPOCH*100,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "\n",
    "    # Callbackks \n",
    "    # EarlyStopping\n",
    "    checkpoint = ModelCheckpoint(\n",
    "            filepath='../saved_models/last_saved_model.keras',\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "            )\n",
    "    # checkpoint = ModelCheckpoint('model.h5', save_best_only=True, save_format='h5', verbose=1)\n",
    "    earlyStoppingCallback = EarlyStopping(monitor='val_loss',\n",
    "                                             start_from_epoch=10,\n",
    "                                             restore_best_weights=True,\n",
    "                                             verbose=0,\n",
    "                                             patience=5)\n",
    "\n",
    "    def get_optimizer():\n",
    "         # return tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        return tf.keras.optimizers.Adam(learning_rate= lr_schedule) # type: ignore\n",
    "\n",
    "    optimizer = get_optimizer()\n",
    "\n",
    "    # defining loss function, optimizer, metrics and then compiling model\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(x_train, y_train, epochs=nb_epoch, batch_size=batch_size, \n",
    "                        shuffle=False, validation_data=(x_test, y_test), callbacks=[checkpoint, earlyStoppingCallback], verbose=2) # type: ignore\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (56, 150, 4)\n",
      "Timesteps: 150\n",
      "Num Samples: 56\n",
      "Test Samples: 10\n",
      "Num features: 4\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, Y_test = data(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step\n",
      "[[0.11021952 0.8799596 ]\n",
      " [0.11442844 0.8766697 ]\n",
      " [0.11815286 0.87392056]\n",
      " [0.12862694 0.8651782 ]\n",
      " [0.14222674 0.85345703]\n",
      " [0.15988606 0.83797586]\n",
      " [0.17235628 0.8274266 ]\n",
      " [0.18302582 0.8183488 ]\n",
      " [0.1878275  0.8144575 ]\n",
      " [0.1906147  0.81189615]]\n",
      "[[1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "[[ 1.    0.   83.37 83.25 83.37 83.24]\n",
      " [ 0.    1.   83.41 83.38 83.42 83.33]\n",
      " [ 0.    1.   83.35 83.42 83.43 83.32]\n",
      " [ 0.    1.   83.38 83.34 83.4  83.31]\n",
      " [ 0.    1.   83.39 83.38 83.43 83.38]\n",
      " [ 0.    1.   83.49 83.38 83.51 83.37]\n",
      " [ 1.    0.   83.5  83.49 83.52 83.46]\n",
      " [ 1.    0.   83.6  83.51 83.6  83.48]\n",
      " [ 1.    0.   83.67 83.61 83.69 83.59]\n",
      " [ 1.    0.   83.66 83.68 83.7  83.63]]\n",
      "[[ 0.    1.   83.37 83.25 83.37 83.24]\n",
      " [ 0.    1.   83.41 83.38 83.42 83.33]\n",
      " [ 0.    1.   83.35 83.42 83.43 83.32]\n",
      " [ 0.    1.   83.38 83.34 83.4  83.31]\n",
      " [ 0.    1.   83.39 83.38 83.43 83.38]\n",
      " [ 0.    1.   83.49 83.38 83.51 83.37]\n",
      " [ 0.    1.   83.5  83.49 83.52 83.46]\n",
      " [ 0.    1.   83.6  83.51 83.6  83.48]\n",
      " [ 0.    1.   83.67 83.61 83.69 83.59]\n",
      " [ 0.    1.   83.66 83.68 83.7  83.63]]\n",
      "   Sell  Buy  Close   Open   High    Low\n",
      "0   1.0  0.0  83.37  83.25  83.37  83.24\n",
      "1   0.0  1.0  83.41  83.38  83.42  83.33\n",
      "2   0.0  1.0  83.35  83.42  83.43  83.32\n",
      "3   0.0  1.0  83.38  83.34  83.40  83.31\n",
      "4   0.0  1.0  83.39  83.38  83.43  83.38\n",
      "5   0.0  1.0  83.49  83.38  83.51  83.37\n",
      "6   1.0  0.0  83.50  83.49  83.52  83.46\n",
      "7   1.0  0.0  83.60  83.51  83.60  83.48\n",
      "8   1.0  0.0  83.67  83.61  83.69  83.59\n",
      "9   1.0  0.0  83.66  83.68  83.70  83.63\n",
      "-0.12\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(filepath=\"../saved_models/last_saved_model.keras\") \n",
    "# loaded_model.summary()\n",
    "predict = loaded_model.predict(x_test)\n",
    "print(predict)\n",
    "predict = np.array([[1,0],[0,1],[0,1],[0,1],[0,1],[0,1],[1,0],[1,0],[1,0],[1,0]])\n",
    "predict_classes = np.where(predict > 0.5, 1,0)\n",
    "print(predict_classes)\n",
    "concat = np.hstack((predict_classes, Y_test[:,2:]))\n",
    "print(concat)\n",
    "print(Y_test)\n",
    "dfToProfit = pd.DataFrame(concat, columns=['Sell', 'Buy', 'Close', 'Open', 'High', 'Low'])\n",
    "print(dfToProfit)\n",
    "print(funcProfit(dfToProfit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sell  Buy  Close   Open   High    Low\n",
      "0   1.0  0.0  83.37  83.25  83.37  83.24\n",
      "1   0.0  1.0  83.41  83.38  83.42  83.33\n",
      "2   0.0  1.0  83.35  83.42  83.43  83.32\n",
      "3   0.0  1.0  83.38  83.34  83.40  83.31\n",
      "4   0.0  1.0  83.39  83.38  83.43  83.38\n",
      "5   0.0  1.0  83.49  83.38  83.51  83.37\n",
      "6   1.0  0.0  83.50  83.49  83.52  83.46\n",
      "7   1.0  0.0  83.60  83.51  83.60  83.48\n",
      "8   1.0  0.0  83.67  83.61  83.69  83.59\n",
      "9   1.0  0.0  83.66  83.68  83.70  83.63\n"
     ]
    }
   ],
   "source": [
    "print(dfToProfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "0.2 != -0.02",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 56\u001b[0m\n\u001b[0;32m     52\u001b[0m     test \u001b[38;5;241m=\u001b[39m unittest\u001b[38;5;241m.\u001b[39mTestCase()\n\u001b[0;32m     54\u001b[0m     test\u001b[38;5;241m.\u001b[39massertEqual(funcProfit(dfToProfit), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.02\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[43mtest_profit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[89], line 54\u001b[0m, in \u001b[0;36mtest_profit\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_profit\u001b[39m():\n\u001b[0;32m     52\u001b[0m     test \u001b[38;5;241m=\u001b[39m unittest\u001b[38;5;241m.\u001b[39mTestCase()\n\u001b[1;32m---> 54\u001b[0m     \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massertEqual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuncProfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfToProfit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\.conda\\envs\\tf_env\\lib\\unittest\\case.py:845\u001b[0m, in \u001b[0;36mTestCase.assertEqual\u001b[1;34m(self, first, second, msg)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fail if the two objects are unequal as determined by the '=='\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;124;03m   operator.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    844\u001b[0m assertion_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getAssertEqualityFunc(first, second)\n\u001b[1;32m--> 845\u001b[0m \u001b[43massertion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\.conda\\envs\\tf_env\\lib\\unittest\\case.py:838\u001b[0m, in \u001b[0;36mTestCase._baseAssertEqual\u001b[1;34m(self, first, second, msg)\u001b[0m\n\u001b[0;32m    836\u001b[0m standardMsg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m _common_shorten_repr(first, second)\n\u001b[0;32m    837\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_formatMessage(msg, standardMsg)\n\u001b[1;32m--> 838\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfailureException(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: 0.2 != -0.02"
     ]
    }
   ],
   "source": [
    "# Profit\n",
    "import unittest\n",
    "def funcProfit(df):\n",
    "    # predict_classes = np.where(predict > 0.5, 1,0)\n",
    "    # concat = np.hstack((predict_classes, Y_test[:,2:]))\n",
    "    # df = pd.DataFrame(concat, columns=['Sell', 'Buy', 'Price'])\n",
    "\n",
    "    # Absolute difference prices\n",
    "    spread = 0.03\n",
    "    tp = 0.20\n",
    "    sum = 0\n",
    "    sell = 0\n",
    "    buy = 0\n",
    "    for i in range(0, len(df)):\n",
    "        if (i-1) >= 0:\n",
    "            if df.at[i,'Sell'] > 0.8 and df.at[i-1,'Sell'] < 0.2:                  # S 0 1 \n",
    "                if buy > 0:\n",
    "                    sell = df.at[i,'Open'] - spread\n",
    "                    sum += df.at[i,'Open'] - buy\n",
    "                    buy = 0\n",
    "                elif sell == 0:\n",
    "                    sell = df.at[i,'Open'] - spread\n",
    "            elif df.at[i,'Sell'] > 0.8 and df.at[i-1,'Sell'] > 0.8 and sell > 0:   # S 1 1 sell >0\n",
    "                if df.at[i-1,'High'] >= (sell + tp):\n",
    "                    sum -= tp\n",
    "                    sell = 0\n",
    "                if df.at[i-1,'Low'] <= (sell - tp):\n",
    "                    sum += tp\n",
    "                    sell = 0\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "            elif df.at[i,'Buy'] > 0.8 and df.at[i-1,'Buy'] < 0.2:               # B 0 1 \n",
    "                if sell > 0:\n",
    "                    buy = df.at[i,'Open'] + spread\n",
    "                    sum += sell - df.at[i,'Open']\n",
    "                    sell = 0\n",
    "                elif buy == 0:\n",
    "                    buy = df.at[i,'Open'] + spread\n",
    "            elif df.at[i,'Buy'] > 0.8 and df.at[i-1,'Buy'] > 0.8 and buy > 0:   # B 1 1 buy >0\n",
    "                if df.at[i-1,'Low'] <= (buy - tp):\n",
    "                    sum -= tp\n",
    "                    buy = 0\n",
    "                if df.at[i-1,'High'] >= (buy + tp):\n",
    "                    sum += tp\n",
    "                    buy = 0\n",
    "\n",
    "    return round(sum, 2)\n",
    "\n",
    "print(funcProfit(dfToProfit))\n",
    "\n",
    "def test_profit():\n",
    "    test = unittest.TestCase()\n",
    "\n",
    "    test.assertEqual(funcProfit(dfToProfit), -0.02)\n",
    "\n",
    "test_profit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment\n",
    "def experiment(repeats, epochs, neurons, time, denseType, dropout, model):\n",
    "    # Data gen\n",
    "    x_train, x_test, y_train, y_test, Y_test = data(time)\n",
    "\n",
    "    # Evaluate declaration\n",
    "    accuracy = list()\n",
    "    profit = list()\n",
    "    metrics = list()\n",
    "\n",
    "    # Repeats\n",
    "    for r in range(repeats):\n",
    "        \n",
    "        # Print running\n",
    "        print(f\"Repeat {r} running...\")\n",
    "\n",
    "        # Batch size\n",
    "        batch_size = 64\n",
    "        # model\n",
    "        model, history = fit_lstmModel(x_train, y_train, x_test, y_test, batch_size, epochs, neurons, denseType, dropout, model)\n",
    "\n",
    "        # forecast the entire training dataset to build up state for forecasting\n",
    "        predict = model.predict(x_test, batch_size=batch_size)\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0) # type: ignore\n",
    "\n",
    "        metric = pd.DataFrame(history.history)\n",
    "        metric['epoch'] = history.epoch\n",
    "\n",
    "        metrics.append(metric)\n",
    "        accuracy.append(test_acc*100)\n",
    "        profit.append(funcProfit(predict, Y_test))\n",
    "    \n",
    "    return accuracy, profit, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "def plotsOut(d, metrics):\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=('Accuracy', 'Loss'))\n",
    "\n",
    "    # Layout - set size\n",
    "    fig.update_layout(\n",
    "        autosize=True,\n",
    "        width=1000\n",
    "    )\n",
    "\n",
    "    for idx, m in enumerate(metrics):\n",
    "        fig.add_trace(go.Scatter(x=m['epoch'], y=m['accuracy'], name=f'accuracy{str(idx)}', line_color='#0000ff', showlegend=False), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=m['epoch'], y=m['loss'], name=f'loss{str(idx)}', line_color='#0000ff', showlegend=False), row=1, col=2)\n",
    "        fig.add_trace(go.Scatter(x=m['epoch'], y=m['val_accuracy'], name=f'val_accuracy{str(idx)}', line_color='#EF8260', showlegend=False), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=m['epoch'], y=m['val_loss'], name=f'val_loss{str(idx)}', line_color='#EF8260', showlegend=False), row=1, col=2)\n",
    "\n",
    "    fig.update_xaxes(title_text='epochs')\n",
    "    fig.update_yaxes(title_text='')\n",
    "    # fig.update_layout(width=1000, title='Accuracy and Loss')\n",
    "    fig.write_image(file=f\"compare_models_{str(d)}.jpg\", engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Model test start...\n",
      "Train shape: (850, 150, 4)\n",
      "Timesteps: 150\n",
      "Num Samples: 850\n",
      "Test Samples: 150\n",
      "Num features: 4\n",
      "Repeat 0 running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">93,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">302</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │        \u001b[38;5;34m93,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m302\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,302</span> (364.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,302\u001b[0m (364.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,302</span> (364.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m93,302\u001b[0m (364.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.66093, saving model to ../saved_models/last_saved_model.keras\n",
      "14/14 - 11s - 806ms/step - accuracy: 0.5353 - loss: 0.7034 - val_accuracy: 0.7133 - val_loss: 0.6609\n",
      "Epoch 2/5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.66093 to 0.63639, saving model to ../saved_models/last_saved_model.keras\n",
      "14/14 - 3s - 248ms/step - accuracy: 0.6071 - loss: 0.6635 - val_accuracy: 0.7133 - val_loss: 0.6364\n",
      "Epoch 3/5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.63639 to 0.60948, saving model to ../saved_models/last_saved_model.keras\n",
      "14/14 - 5s - 363ms/step - accuracy: 0.6024 - loss: 0.6479 - val_accuracy: 0.7067 - val_loss: 0.6095\n",
      "Epoch 4/5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.60948 to 0.57446, saving model to ../saved_models/last_saved_model.keras\n",
      "14/14 - 3s - 243ms/step - accuracy: 0.6365 - loss: 0.6323 - val_accuracy: 0.7667 - val_loss: 0.5745\n",
      "Epoch 5/5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.57446 to 0.53508, saving model to ../saved_models/last_saved_model.keras\n",
      "14/14 - 6s - 404ms/step - accuracy: 0.6694 - loss: 0.6239 - val_accuracy: 0.8133 - val_loss: 0.5351\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "funcProfit() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m model:\n\u001b[0;32m     17\u001b[0m  \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Model test start...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m  results_acc[\u001b[38;5;28mstr\u001b[39m(mod)], results_profit[\u001b[38;5;28mstr\u001b[39m(mod)], metrics \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneuronsLstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeStep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenseType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#  plotsOut(mod, metrics)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# summarize results\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_acc\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "Cell \u001b[1;32mIn[80], line 31\u001b[0m, in \u001b[0;36mexperiment\u001b[1;34m(repeats, epochs, neurons, time, denseType, dropout, model)\u001b[0m\n\u001b[0;32m     29\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mappend(metric)\n\u001b[0;32m     30\u001b[0m     accuracy\u001b[38;5;241m.\u001b[39mappend(test_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m     profit\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfuncProfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy, profit, metrics\n",
      "\u001b[1;31mTypeError\u001b[0m: funcProfit() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "from numpy import dtype\n",
    "\n",
    "repeats = 1\n",
    "results_acc = DataFrame(dtype='float')\n",
    "results_profit = DataFrame(dtype='float')\n",
    "metrics = list()\n",
    "\n",
    "# vary training epochs\n",
    "model = [0]\n",
    "dropout = 0.2\n",
    "denseType = 0\n",
    "neuronsLstm = 150\n",
    "timeStep = 150\n",
    "epochs = 5\n",
    "for mod in model:\n",
    " print(f\"{mod} Model test start...\")\n",
    " results_acc[str(mod)], results_profit[str(mod)], metrics = experiment(repeats, epochs, neuronsLstm, timeStep, denseType, dropout, mod)\n",
    "#  plotsOut(mod, metrics)\n",
    "\n",
    "# summarize results\n",
    "print(results_acc.describe())\n",
    "print(results_profit.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(results_acc.describe())\n",
    "print(results_profit.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print(results_acc.describe())\n",
    "\n",
    "# 2 subplots in one row\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "# Generate boxplots\n",
    "results_acc.boxplot(ax=ax[0])\n",
    "results_profit.boxplot(ax=ax[1])\n",
    "\n",
    "# Set labels and titles\n",
    "ax[0].set_title('Accuracy')\n",
    "ax[0].set_xlabel('Dropout')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[1].set_title('Profit')\n",
    "ax[1].set_xlabel('Dropout')\n",
    "ax[1].set_ylabel('Profit')\n",
    "\n",
    "# Save to .png and show plot\n",
    "plt.savefig(f'boxplot_model.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
